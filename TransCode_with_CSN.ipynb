{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0oOH4jveRaP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install -q transformers datasets\n",
        "!pip install -q pytorch-lightning wandb\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUT9392IR3MZ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"code_search_net\", \"python\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdpm7pHoU7t1"
      },
      "outputs": [],
      "source": [
        "example = dataset['train'][0]\n",
        "\n",
        "print(\"Code:\", example[\"whole_func_string\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhsmB19ceRaW"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune\")\n",
        "\n",
        "prefix = \"Summarize Python: \"\n",
        "max_input_length = 256\n",
        "max_target_length = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvRHDkCIS91f"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def preprocess_examples(examples):\n",
        "  # encode the code-docstring pairs\n",
        "    codes = examples['whole_func_string']\n",
        "    docstrings = examples['func_documentation_string']\n",
        "  \n",
        "    inputs = [prefix + code for code in codes]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, padding=\"max_length\", truncation=True)\n",
        "\n",
        "  # encode the summaries\n",
        "    labels = tokenizer(docstrings, max_length=max_target_length, padding=\"max_length\", truncation=True).input_ids\n",
        "\n",
        "\n",
        "    labels_with_ignore_index = []\n",
        "    for labels_example in labels:\n",
        "        labels_example = [label if label != 0 else -100 for label in labels_example]\n",
        "        labels_with_ignore_index.append(labels_example)\n",
        "  \n",
        "    model_inputs[\"labels\"] = labels_with_ignore_index\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2lYwT-ZWMk0"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(preprocess_examples, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nevKo-Sob21L"
      },
      "outputs": [],
      "source": [
        "# dataset['train'][1]['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCPeOdkXeRaY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq2-xLG_alXH"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset['train'], shuffle=True, batch_size=8)\n",
        "valid_dataloader = DataLoader(dataset['validation'], batch_size=4)\n",
        "test_dataloader = DataLoader(dataset['test'], batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y0l7v8obmml"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH4MIhxFc2BR"
      },
      "source": [
        "Let's verify an example, by decoding it back into text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsqjA1OHcn5V"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(batch['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYQWyCDzcqzh"
      },
      "outputs": [],
      "source": [
        "labels = batch['labels'][0]\n",
        "tokenizer.decode([label for label in labels if label != -100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOxapqxzS0PO"
      },
      "source": [
        "## Fine-tune using PyTorch Lightning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuHlP1MuR_tJ"
      },
      "outputs": [],
      "source": [
        "from transformers import  AutoModelWithLMHead, AdamW, get_linear_schedule_with_warmup\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class CodeTrans(pl.LightningModule):\n",
        "    def __init__(self, lr=5e-5, num_train_epochs=1, warmup_steps=1000):\n",
        "        super().__init__()\n",
        "        self.model = AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune\")\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):     \n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        return outputs\n",
        "    \n",
        "    def common_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        return loss\n",
        "      \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.common_step(batch, batch_idx)     \n",
        "        # logs metrics for each training_step,\n",
        "        # and the average across the epoch\n",
        "        self.log(\"training_loss\", loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.common_step(batch, batch_idx)     \n",
        "        self.log(\"validation_loss\", loss, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss = self.common_step(batch, batch_idx)     \n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # create optimizer\n",
        "        optimizer = AdamW(self.parameters(), lr=self.hparams.lr)\n",
        "        # create learning rate scheduler\n",
        "        num_train_optimization_steps = self.hparams.num_train_epochs * len(train_dataloader)\n",
        "        lr_scheduler = {'scheduler': get_linear_schedule_with_warmup(optimizer,\n",
        "                                                    num_warmup_steps=self.hparams.warmup_steps,\n",
        "                                                    num_training_steps=num_train_optimization_steps),\n",
        "                        'name': 'learning_rate',\n",
        "                        'interval':'step',\n",
        "                        'frequency': 1}\n",
        "        \n",
        "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return train_dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return valid_dataloader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return test_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuYF6-tYZuuN"
      },
      "source": [
        "Let's start up Weights and Biases!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKDavW52ZuKv"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAxLx7_Td1G-"
      },
      "source": [
        "Next, we initialize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtDmLYzEc9uP"
      },
      "outputs": [],
      "source": [
        "model = CodeTrans()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPzgguodd2uS"
      },
      "source": [
        "We can now simply start training on Colab's GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WroP64V8dWuO"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
        "\n",
        "wandb_logger = WandbLogger(name='codetrans-finetune', project='CodeTrans')\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor='validation_loss',\n",
        "    patience=3,\n",
        "    strict=False,\n",
        "    verbose=False,\n",
        "    mode='min'\n",
        ")\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
        "\n",
        "trainer = Trainer(gpus=1, \n",
        "                  default_root_dir=None, \n",
        "                  logger=wandb_logger, \n",
        "                  callbacks=[early_stop_callback, lr_monitor])\n",
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QBSyDyTeRab"
      },
      "source": [
        "## Save the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhfLMOAmhIG6"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.save_pretrained(save_directory=\"CodeTrans_CSN\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr0O3iN5IsdW"
      },
      "source": [
        "This allows us to easily load the trained model again using the `from_pretrained()` method, as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzhasngvAwX3"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now that we've trained a model, let's test it on some examples from the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPXM9tH8AyCN"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"code_search_net\", \"python\")\n",
        "print(dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spbNHeE5ETpG"
      },
      "outputs": [],
      "source": [
        "test_example = dataset['test'][2]\n",
        "print(\"Code:\", test_example['whole_func_string'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XwCaigDI622"
      },
      "source": [
        "We can load our trained model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu68VMzTEXek"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"save_directory\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"CT5_CSN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhpiAr6UE7vG"
      },
      "outputs": [],
      "source": [
        "# prepare for the model\n",
        "input_ids = tokenizer(test_example['whole_func_string'], return_tensors='pt').input_ids\n",
        "# input_ids = tokenizer(test_example, return_tensors='pt').input_ids\n",
        "# generate\n",
        "outputs = model.generate(input_ids)\n",
        "print(\"Generated Docstring:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjxvMu0rKDzL"
      },
      "source": [
        "Let's compare this to the ground-truth docstring:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLy5iUqHKHmy"
      },
      "outputs": [],
      "source": [
        "print(\"Actual Docstring:\", test_example['func_documentation_string'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}